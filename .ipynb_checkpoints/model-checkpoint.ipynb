{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./titanic/train.csv')\n",
    "test = pd.read_csv('./titanic/test.csv')\n",
    "sub=pd.read_csv('./titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milad\\AppData\\Local\\Temp/ipykernel_16824/3060123638.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
      "C:\\Users\\Milad\\AppData\\Local\\Temp/ipykernel_16824/3060123638.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing & feature engineering \n",
    "\n",
    "full_data = [train, test]\n",
    "\n",
    "for dataset in full_data:\n",
    "    \n",
    "    dataset['Ticket_type'] = dataset['Ticket'].apply(lambda x: x[0:3])\n",
    "    dataset['Ticket_type'] = dataset['Ticket_type'].astype('category')\n",
    "    dataset['Ticket_type'] = dataset['Ticket_type'].cat.codes\n",
    "    \n",
    "    dataset['Words_Count'] = dataset['Name'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    dataset['Has_Cabin'] = dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    \n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    \n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "    \n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    \n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int) # mapping sex\n",
    "    \n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_type</th>\n",
       "      <th>Words_Count</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  Parch  Fare  Embarked  Ticket_type  \\\n",
       "886         0       2    1    1      0     1         0           23   \n",
       "887         1       1    0    1      0     2         0            2   \n",
       "888         0       3    0    2      2     2         0          150   \n",
       "889         1       1    1    1      0     2         1            1   \n",
       "890         0       3    1    1      0     0         2           94   \n",
       "\n",
       "     Words_Count  Has_Cabin  FamilySize  IsAlone  Title  \n",
       "886            3          0           1        1      5  \n",
       "887            4          1           1        1      2  \n",
       "888            5          0           4        0      2  \n",
       "889            4          1           1        1      1  \n",
       "890            3          0           1        1      1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_type</th>\n",
       "      <th>Words_Count</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Parch  Fare  Embarked  Ticket_type  Words_Count  \\\n",
       "0       3    1    2      0     0         2           58            3   \n",
       "1       3    0    2      0     0         0           71            5   \n",
       "2       2    1    3      0     1         2           32            4   \n",
       "3       3    1    1      0     1         0           55            3   \n",
       "4       3    0    1      1     1         0           54            6   \n",
       "\n",
       "   Has_Cabin  FamilySize  IsAlone  Title  \n",
       "0          0           1        1      1  \n",
       "1          0           2        0      3  \n",
       "2          0           1        1      1  \n",
       "3          0           1        1      1  \n",
       "4          0           3        0      3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(\"Survived\",axis=1).values\n",
    "y=train[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "test_scaled=scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "# input layer\n",
    "model.add(Dense(78,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# hidden layer\n",
    "model.add(Dense(39, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# hidden layer\n",
    "model.add(Dense(19, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 1s 22ms/step - loss: 0.6546 - val_loss: 0.6690\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.6397\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.5935\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5538 - val_loss: 0.5392\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5302 - val_loss: 0.5010\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5046 - val_loss: 0.4626\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4762 - val_loss: 0.4555\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4744 - val_loss: 0.4468\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4742 - val_loss: 0.4301\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4774 - val_loss: 0.4323\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4667 - val_loss: 0.4444\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4624 - val_loss: 0.4505\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4486 - val_loss: 0.4384\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4591 - val_loss: 0.4245\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4620 - val_loss: 0.4431\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4622 - val_loss: 0.4442\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4576 - val_loss: 0.4431\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4498 - val_loss: 0.4312\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4424 - val_loss: 0.4335\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4495 - val_loss: 0.4435\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.462 - 0s 4ms/step - loss: 0.4445 - val_loss: 0.4310\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4383 - val_loss: 0.4262\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4463 - val_loss: 0.4244\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4396 - val_loss: 0.4391\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4359 - val_loss: 0.4219\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4240 - val_loss: 0.4287\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4194 - val_loss: 0.4281\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4295 - val_loss: 0.4271\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4253 - val_loss: 0.4299\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4226 - val_loss: 0.4428\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4296 - val_loss: 0.4415\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4206 - val_loss: 0.4401\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4242 - val_loss: 0.4361\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4230 - val_loss: 0.4427\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4263 - val_loss: 0.4458\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4173 - val_loss: 0.4236\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4162 - val_loss: 0.4339\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4221 - val_loss: 0.4467\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4214 - val_loss: 0.4323\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4201 - val_loss: 0.4440\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4169 - val_loss: 0.4312\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4079 - val_loss: 0.4406\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4184 - val_loss: 0.4352\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4099 - val_loss: 0.4330\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4126 - val_loss: 0.4319\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4163 - val_loss: 0.4378\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4098 - val_loss: 0.4259\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4121 - val_loss: 0.4293\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3999 - val_loss: 0.4386\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4086 - val_loss: 0.4302\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4060 - val_loss: 0.4302\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4005 - val_loss: 0.4268\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4084 - val_loss: 0.4255\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4048 - val_loss: 0.4251\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4108 - val_loss: 0.4383\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4058 - val_loss: 0.4360\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4137 - val_loss: 0.4372\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4057 - val_loss: 0.4222\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4077 - val_loss: 0.4289\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4053 - val_loss: 0.4347\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4028 - val_loss: 0.4462\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3905 - val_loss: 0.4281\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3994 - val_loss: 0.4280\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3861 - val_loss: 0.4203\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3941 - val_loss: 0.4269\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4128 - val_loss: 0.4234\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4003 - val_loss: 0.4208\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3911 - val_loss: 0.4337\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3915 - val_loss: 0.4279\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4023 - val_loss: 0.4266\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3931 - val_loss: 0.4177\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4000 - val_loss: 0.4266\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3928 - val_loss: 0.4354\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3891 - val_loss: 0.4107\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.455 - 0s 5ms/step - loss: 0.3909 - val_loss: 0.4171\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3892 - val_loss: 0.4280\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3828 - val_loss: 0.4027\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3803 - val_loss: 0.3905\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3911 - val_loss: 0.4070\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3822 - val_loss: 0.4283\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3847 - val_loss: 0.4105\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3760 - val_loss: 0.4087\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3799 - val_loss: 0.4103\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3800 - val_loss: 0.4204\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3937 - val_loss: 0.4115\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3955 - val_loss: 0.4178\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3882 - val_loss: 0.4088\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3854 - val_loss: 0.4005\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3892 - val_loss: 0.4068\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3752 - val_loss: 0.4059\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3741 - val_loss: 0.4088\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3802 - val_loss: 0.4057\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3718 - val_loss: 0.4115\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3760 - val_loss: 0.3994\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3748 - val_loss: 0.3983\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3850 - val_loss: 0.3999\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3729 - val_loss: 0.4131\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3772 - val_loss: 0.4033\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3718 - val_loss: 0.3945\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3679 - val_loss: 0.4064\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3593 - val_loss: 0.3870\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3771 - val_loss: 0.3896\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3696 - val_loss: 0.4234\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3717 - val_loss: 0.3961\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3646 - val_loss: 0.3882\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.511 - 0s 5ms/step - loss: 0.3641 - val_loss: 0.4140\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3733 - val_loss: 0.4084\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3648 - val_loss: 0.3934\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3802 - val_loss: 0.4263\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3600 - val_loss: 0.4299\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3675 - val_loss: 0.3992\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3570 - val_loss: 0.4010\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3705 - val_loss: 0.4027\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3667 - val_loss: 0.4153\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3583 - val_loss: 0.4146\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3590 - val_loss: 0.4010\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.344 - 0s 5ms/step - loss: 0.3568 - val_loss: 0.4094\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3638 - val_loss: 0.3911\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3601 - val_loss: 0.4044\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3713 - val_loss: 0.3822\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3558 - val_loss: 0.3956\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3666 - val_loss: 0.3767\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3507 - val_loss: 0.3771\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3636 - val_loss: 0.3934\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3557 - val_loss: 0.3760\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3492 - val_loss: 0.3892\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3552 - val_loss: 0.3931\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3542 - val_loss: 0.3720\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3562 - val_loss: 0.3665\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3560 - val_loss: 0.3784\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3461 - val_loss: 0.3844\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3535 - val_loss: 0.3994\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3502 - val_loss: 0.4024\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3407 - val_loss: 0.4005\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3535 - val_loss: 0.3948\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3435 - val_loss: 0.3740\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.342 - 0s 5ms/step - loss: 0.3625 - val_loss: 0.3876\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3528 - val_loss: 0.4063\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3472 - val_loss: 0.3892\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3492 - val_loss: 0.3933\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3546 - val_loss: 0.3726\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3430 - val_loss: 0.4043\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3414 - val_loss: 0.3880\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3430 - val_loss: 0.3812\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3391 - val_loss: 0.3885\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3366 - val_loss: 0.3881\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3441 - val_loss: 0.3664\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3532 - val_loss: 0.3832\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3452 - val_loss: 0.3905\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3338 - val_loss: 0.3857\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.392 - 0s 4ms/step - loss: 0.3520 - val_loss: 0.3828\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3484 - val_loss: 0.4108\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3430 - val_loss: 0.3830\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3405 - val_loss: 0.3820\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3427 - val_loss: 0.3842\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3413 - val_loss: 0.3982\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3386 - val_loss: 0.3725\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3430 - val_loss: 0.3694\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3281 - val_loss: 0.3616\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3311 - val_loss: 0.3758\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3466 - val_loss: 0.3792\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3269 - val_loss: 0.3826\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3364 - val_loss: 0.3734\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3373 - val_loss: 0.3982\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.253 - 0s 4ms/step - loss: 0.3411 - val_loss: 0.3663\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3418 - val_loss: 0.3823\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3273 - val_loss: 0.3494\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3187 - val_loss: 0.3676\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3291 - val_loss: 0.3606\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3333 - val_loss: 0.3682\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3174 - val_loss: 0.3649\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.3827\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3389 - val_loss: 0.3765\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3196 - val_loss: 0.3737\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3265 - val_loss: 0.3700\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3248 - val_loss: 0.3701\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3272 - val_loss: 0.3661\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.3773\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3332 - val_loss: 0.3803\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3306 - val_loss: 0.3723\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3453 - val_loss: 0.3739\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3197 - val_loss: 0.4035\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3248 - val_loss: 0.3957\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3374 - val_loss: 0.3701\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3314 - val_loss: 0.3583\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3289 - val_loss: 0.3631\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3352 - val_loss: 0.3860\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3260 - val_loss: 0.3695\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3187 - val_loss: 0.3775\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3253 - val_loss: 0.3874\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3164 - val_loss: 0.3664\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3110 - val_loss: 0.3689\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3335 - val_loss: 0.3968\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3353 - val_loss: 0.3597\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3115 - val_loss: 0.3498\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3139 - val_loss: 0.3522\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3094 - val_loss: 0.3624\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3215 - val_loss: 0.3675\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3274 - val_loss: 0.3651\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3231 - val_loss: 0.3642\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3175 - val_loss: 0.3729\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3255 - val_loss: 0.3690\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3037 - val_loss: 0.3776\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3253 - val_loss: 0.3655\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3184 - val_loss: 0.3707\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3073 - val_loss: 0.3712\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3210 - val_loss: 0.3660\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3230 - val_loss: 0.3620\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3071 - val_loss: 0.3476\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3228 - val_loss: 0.3695\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.3722\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3041 - val_loss: 0.3686\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3165 - val_loss: 0.3705\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3098 - val_loss: 0.3644\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3120 - val_loss: 0.3679\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3037 - val_loss: 0.3624\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3201 - val_loss: 0.3679\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3185 - val_loss: 0.3686\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3100 - val_loss: 0.3538\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3098 - val_loss: 0.3780\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3119 - val_loss: 0.3574\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2959 - val_loss: 0.3436\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3109 - val_loss: 0.3650\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2965 - val_loss: 0.3522\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.3687\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.3585\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3037 - val_loss: 0.3417\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3090 - val_loss: 0.3276\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2973 - val_loss: 0.3514\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3101 - val_loss: 0.3624\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3012 - val_loss: 0.3508\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3058 - val_loss: 0.3536\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3036 - val_loss: 0.3586\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2969 - val_loss: 0.3618\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3177 - val_loss: 0.3628\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.3548\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2933 - val_loss: 0.3600\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2953 - val_loss: 0.3529\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2988 - val_loss: 0.3515\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2926 - val_loss: 0.3606\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2967 - val_loss: 0.3600\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3034 - val_loss: 0.3762\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3077 - val_loss: 0.3595\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3048 - val_loss: 0.3559\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2986 - val_loss: 0.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2899 - val_loss: 0.3591\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2863 - val_loss: 0.3506\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3140 - val_loss: 0.3643\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2955 - val_loss: 0.3715\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2989 - val_loss: 0.3555\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2959 - val_loss: 0.3511\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2880 - val_loss: 0.3620\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2921 - val_loss: 0.3836\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2970 - val_loss: 0.3676\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2995 - val_loss: 0.3615\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2804 - val_loss: 0.3519\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3051 - val_loss: 0.3468\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.3542\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2930 - val_loss: 0.3634\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3034 - val_loss: 0.3614\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3121 - val_loss: 0.3640\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2968 - val_loss: 0.3498\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2956 - val_loss: 0.3503\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2874 - val_loss: 0.3431\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3009 - val_loss: 0.3634\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3049 - val_loss: 0.3797\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2940 - val_loss: 0.3812\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3106 - val_loss: 0.3731\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2878 - val_loss: 0.3856\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2854 - val_loss: 0.3845\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2792 - val_loss: 0.3590\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.3576\n",
      "Epoch 273/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2797 - val_loss: 0.3876\n",
      "Epoch 274/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2812 - val_loss: 0.3854\n",
      "Epoch 275/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2859 - val_loss: 0.3831\n",
      "Epoch 276/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.3519\n",
      "Epoch 277/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2813 - val_loss: 0.3649\n",
      "Epoch 278/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2947 - val_loss: 0.3760\n",
      "Epoch 279/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.3697\n",
      "Epoch 280/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2785 - val_loss: 0.3836\n",
      "Epoch 281/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2802 - val_loss: 0.4041\n",
      "Epoch 282/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.248 - 0s 5ms/step - loss: 0.2971 - val_loss: 0.3612\n",
      "Epoch 283/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2810 - val_loss: 0.3504\n",
      "Epoch 284/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2866 - val_loss: 0.3396\n",
      "Epoch 285/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2896 - val_loss: 0.3519\n",
      "Epoch 286/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2826 - val_loss: 0.3444\n",
      "Epoch 287/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2753 - val_loss: 0.3477\n",
      "Epoch 288/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2820 - val_loss: 0.3772\n",
      "Epoch 289/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2921 - val_loss: 0.3595\n",
      "Epoch 290/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2844 - val_loss: 0.3748\n",
      "Epoch 291/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2644 - val_loss: 0.3876\n",
      "Epoch 292/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2716 - val_loss: 0.3585\n",
      "Epoch 293/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2831 - val_loss: 0.3732\n",
      "Epoch 294/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.3825\n",
      "Epoch 295/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2791 - val_loss: 0.3675\n",
      "Epoch 296/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.3502\n",
      "Epoch 297/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2840 - val_loss: 0.3835\n",
      "Epoch 298/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2958 - val_loss: 0.3460\n",
      "Epoch 299/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.3462\n",
      "Epoch 300/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2769 - val_loss: 0.3706\n",
      "Epoch 301/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2804 - val_loss: 0.3688\n",
      "Epoch 302/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2904 - val_loss: 0.3734\n",
      "Epoch 303/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2943 - val_loss: 0.3766\n",
      "Epoch 304/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2794 - val_loss: 0.3795\n",
      "Epoch 305/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2823 - val_loss: 0.3688\n",
      "Epoch 306/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2748 - val_loss: 0.3752\n",
      "Epoch 307/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2759 - val_loss: 0.3671\n",
      "Epoch 308/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2644 - val_loss: 0.3856\n",
      "Epoch 309/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.3667\n",
      "Epoch 310/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2665 - val_loss: 0.3463\n",
      "Epoch 311/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2760 - val_loss: 0.3622\n",
      "Epoch 312/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2837 - val_loss: 0.3775\n",
      "Epoch 313/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2629 - val_loss: 0.3762\n",
      "Epoch 314/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2746 - val_loss: 0.3774\n",
      "Epoch 315/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2843 - val_loss: 0.3149\n",
      "Epoch 316/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2826 - val_loss: 0.3484\n",
      "Epoch 317/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2767 - val_loss: 0.3663\n",
      "Epoch 318/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2726 - val_loss: 0.3759\n",
      "Epoch 319/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2816 - val_loss: 0.3597\n",
      "Epoch 320/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2649 - val_loss: 0.3719\n",
      "Epoch 321/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2596 - val_loss: 0.3553\n",
      "Epoch 322/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.3592\n",
      "Epoch 323/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2607 - val_loss: 0.3863\n",
      "Epoch 324/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2732 - val_loss: 0.4173\n",
      "Epoch 325/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2746 - val_loss: 0.4071\n",
      "Epoch 326/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2747 - val_loss: 0.4072\n",
      "Epoch 327/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2742 - val_loss: 0.3887\n",
      "Epoch 328/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2659 - val_loss: 0.3791\n",
      "Epoch 329/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.4059\n",
      "Epoch 330/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2843 - val_loss: 0.3960\n",
      "Epoch 331/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2848 - val_loss: 0.3772\n",
      "Epoch 332/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2758 - val_loss: 0.3796\n",
      "Epoch 333/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2678 - val_loss: 0.3670\n",
      "Epoch 334/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.3564\n",
      "Epoch 335/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2707 - val_loss: 0.3709\n",
      "Epoch 336/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2672 - val_loss: 0.3780\n",
      "Epoch 337/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2725 - val_loss: 0.3910\n",
      "Epoch 338/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2612 - val_loss: 0.3648\n",
      "Epoch 339/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2646 - val_loss: 0.3509\n",
      "Epoch 340/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2707 - val_loss: 0.3700\n",
      "Epoch 341/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.303 - 0s 5ms/step - loss: 0.2624 - val_loss: 0.3781\n",
      "Epoch 342/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2670 - val_loss: 0.3777\n",
      "Epoch 343/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2752 - val_loss: 0.3897\n",
      "Epoch 344/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2472 - val_loss: 0.3670\n",
      "Epoch 345/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2580 - val_loss: 0.3831\n",
      "Epoch 346/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2563 - val_loss: 0.3813\n",
      "Epoch 347/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2666 - val_loss: 0.3808\n",
      "Epoch 348/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2811 - val_loss: 0.3641\n",
      "Epoch 349/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2723 - val_loss: 0.3769\n",
      "Epoch 350/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2702 - val_loss: 0.3551\n",
      "Epoch 351/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2696 - val_loss: 0.3504\n",
      "Epoch 352/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.3831\n",
      "Epoch 353/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2710 - val_loss: 0.3889\n",
      "Epoch 354/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2648 - val_loss: 0.3827\n",
      "Epoch 355/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2640 - val_loss: 0.3762\n",
      "Epoch 356/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2651 - val_loss: 0.4075\n",
      "Epoch 357/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2678 - val_loss: 0.4021\n",
      "Epoch 358/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2702 - val_loss: 0.4047\n",
      "Epoch 359/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2551 - val_loss: 0.3764\n",
      "Epoch 360/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2611 - val_loss: 0.3834\n",
      "Epoch 361/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2503 - val_loss: 0.4092\n",
      "Epoch 362/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2512 - val_loss: 0.4038\n",
      "Epoch 363/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2631 - val_loss: 0.4047\n",
      "Epoch 364/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2557 - val_loss: 0.4042\n",
      "Epoch 365/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2615 - val_loss: 0.4014\n",
      "Epoch 366/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2474 - val_loss: 0.3809\n",
      "Epoch 367/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2664 - val_loss: 0.3704\n",
      "Epoch 368/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.3782\n",
      "Epoch 369/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2589 - val_loss: 0.4049\n",
      "Epoch 370/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2661 - val_loss: 0.3793\n",
      "Epoch 371/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2480 - val_loss: 0.3729\n",
      "Epoch 372/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2707 - val_loss: 0.3949\n",
      "Epoch 373/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.339 - 0s 5ms/step - loss: 0.2686 - val_loss: 0.3982\n",
      "Epoch 374/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2478 - val_loss: 0.4105\n",
      "Epoch 375/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.3951\n",
      "Epoch 376/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2674 - val_loss: 0.3778\n",
      "Epoch 377/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2724 - val_loss: 0.3911\n",
      "Epoch 378/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.4062\n",
      "Epoch 379/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2561 - val_loss: 0.3923\n",
      "Epoch 380/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2655 - val_loss: 0.3966\n",
      "Epoch 381/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2562 - val_loss: 0.4022\n",
      "Epoch 382/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2559 - val_loss: 0.4144\n",
      "Epoch 383/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2538 - val_loss: 0.4099\n",
      "Epoch 384/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2586 - val_loss: 0.4173\n",
      "Epoch 385/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2601 - val_loss: 0.4094\n",
      "Epoch 386/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2700 - val_loss: 0.4030\n",
      "Epoch 387/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2388 - val_loss: 0.4190\n",
      "Epoch 388/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2549 - val_loss: 0.4131\n",
      "Epoch 389/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2516 - val_loss: 0.4057\n",
      "Epoch 390/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2622 - val_loss: 0.4368\n",
      "Epoch 391/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2536 - val_loss: 0.4402\n",
      "Epoch 392/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2757 - val_loss: 0.3931\n",
      "Epoch 393/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2613 - val_loss: 0.3749\n",
      "Epoch 394/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.3692\n",
      "Epoch 395/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2622 - val_loss: 0.3848\n",
      "Epoch 396/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2563 - val_loss: 0.3808\n",
      "Epoch 397/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2555 - val_loss: 0.3796\n",
      "Epoch 398/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2550 - val_loss: 0.3949\n",
      "Epoch 399/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2438 - val_loss: 0.4048\n",
      "Epoch 400/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2613 - val_loss: 0.3987\n",
      "Epoch 401/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2527 - val_loss: 0.3936\n",
      "Epoch 402/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2561 - val_loss: 0.4085\n",
      "Epoch 403/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2704 - val_loss: 0.3906\n",
      "Epoch 404/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2552 - val_loss: 0.3695\n",
      "Epoch 405/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2409 - val_loss: 0.3756\n",
      "Epoch 406/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2478 - val_loss: 0.3993\n",
      "Epoch 407/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2522 - val_loss: 0.4045\n",
      "Epoch 408/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2452 - val_loss: 0.3984\n",
      "Epoch 409/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2622 - val_loss: 0.4263\n",
      "Epoch 410/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2484 - val_loss: 0.4161\n",
      "Epoch 411/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2538 - val_loss: 0.3995\n",
      "Epoch 412/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2532 - val_loss: 0.4103\n",
      "Epoch 413/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2542 - val_loss: 0.4032\n",
      "Epoch 414/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2529 - val_loss: 0.4027\n",
      "Epoch 415/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2483 - val_loss: 0.4130\n",
      "Epoch 416/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2450 - val_loss: 0.4172\n",
      "Epoch 417/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2480 - val_loss: 0.4139\n",
      "Epoch 418/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2532 - val_loss: 0.4397\n",
      "Epoch 419/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2503 - val_loss: 0.4345\n",
      "Epoch 420/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.4032\n",
      "Epoch 421/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2349 - val_loss: 0.4138\n",
      "Epoch 422/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2512 - val_loss: 0.4372\n",
      "Epoch 423/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2412 - val_loss: 0.4170\n",
      "Epoch 424/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2464 - val_loss: 0.4033\n",
      "Epoch 425/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2627 - val_loss: 0.4464\n",
      "Epoch 426/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2453 - val_loss: 0.4426\n",
      "Epoch 427/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2391 - val_loss: 0.4513\n",
      "Epoch 428/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2473 - val_loss: 0.4433\n",
      "Epoch 429/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2586 - val_loss: 0.4230\n",
      "Epoch 430/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2505 - val_loss: 0.4107\n",
      "Epoch 431/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2443 - val_loss: 0.4262\n",
      "Epoch 432/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2562 - val_loss: 0.4333\n",
      "Epoch 433/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2557 - val_loss: 0.4159\n",
      "Epoch 434/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2615 - val_loss: 0.4036\n",
      "Epoch 435/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2434 - val_loss: 0.4038\n",
      "Epoch 436/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2451 - val_loss: 0.4280\n",
      "Epoch 437/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2382 - val_loss: 0.4347\n",
      "Epoch 438/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2478 - val_loss: 0.4274\n",
      "Epoch 439/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2543 - val_loss: 0.4345\n",
      "Epoch 440/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2379 - val_loss: 0.4228\n",
      "Epoch 441/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2459 - val_loss: 0.4407\n",
      "Epoch 442/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2606 - val_loss: 0.4613\n",
      "Epoch 443/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2475 - val_loss: 0.4435\n",
      "Epoch 444/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2349 - val_loss: 0.4350\n",
      "Epoch 445/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2472 - val_loss: 0.4597\n",
      "Epoch 446/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2457 - val_loss: 0.4539\n",
      "Epoch 447/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2437 - val_loss: 0.4292\n",
      "Epoch 448/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2294 - val_loss: 0.4401\n",
      "Epoch 449/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2491 - val_loss: 0.4576\n",
      "Epoch 450/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.207 - 0s 5ms/step - loss: 0.2503 - val_loss: 0.4480\n",
      "Epoch 451/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2433 - val_loss: 0.4263\n",
      "Epoch 452/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2433 - val_loss: 0.4280\n",
      "Epoch 453/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2456 - val_loss: 0.3969\n",
      "Epoch 454/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2378 - val_loss: 0.4042\n",
      "Epoch 455/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2402 - val_loss: 0.4098\n",
      "Epoch 456/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2406 - val_loss: 0.4161\n",
      "Epoch 457/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2328 - val_loss: 0.4385\n",
      "Epoch 458/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2457 - val_loss: 0.4384\n",
      "Epoch 459/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2447 - val_loss: 0.4336\n",
      "Epoch 460/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2373 - val_loss: 0.4391\n",
      "Epoch 461/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2469 - val_loss: 0.4294\n",
      "Epoch 462/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.4349\n",
      "Epoch 463/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2379 - val_loss: 0.4360\n",
      "Epoch 464/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2368 - val_loss: 0.4408\n",
      "Epoch 465/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2280 - val_loss: 0.4531\n",
      "Epoch 466/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2265 - val_loss: 0.4646\n",
      "Epoch 467/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2413 - val_loss: 0.4626\n",
      "Epoch 468/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2215 - val_loss: 0.4846\n",
      "Epoch 469/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2459 - val_loss: 0.4764\n",
      "Epoch 470/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2190 - val_loss: 0.4666\n",
      "Epoch 471/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2457 - val_loss: 0.4520\n",
      "Epoch 472/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2231 - val_loss: 0.4280\n",
      "Epoch 473/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2396 - val_loss: 0.3917\n",
      "Epoch 474/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2280 - val_loss: 0.3960\n",
      "Epoch 475/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2403 - val_loss: 0.4353\n",
      "Epoch 476/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2339 - val_loss: 0.4724\n",
      "Epoch 477/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2374 - val_loss: 0.4696\n",
      "Epoch 478/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2320 - val_loss: 0.4582\n",
      "Epoch 479/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2367 - val_loss: 0.4632\n",
      "Epoch 480/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2337 - val_loss: 0.4424\n",
      "Epoch 481/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2445 - val_loss: 0.4648\n",
      "Epoch 482/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2273 - val_loss: 0.4584\n",
      "Epoch 483/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2416 - val_loss: 0.4371\n",
      "Epoch 484/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2303 - val_loss: 0.4620\n",
      "Epoch 485/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2181 - val_loss: 0.4699\n",
      "Epoch 486/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2366 - val_loss: 0.4838\n",
      "Epoch 487/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2316 - val_loss: 0.4912\n",
      "Epoch 488/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2312 - val_loss: 0.4768\n",
      "Epoch 489/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2354 - val_loss: 0.4747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2420 - val_loss: 0.4940\n",
      "Epoch 491/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2337 - val_loss: 0.4923\n",
      "Epoch 492/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2375 - val_loss: 0.4551\n",
      "Epoch 493/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2287 - val_loss: 0.4496\n",
      "Epoch 494/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2345 - val_loss: 0.4239\n",
      "Epoch 495/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2241 - val_loss: 0.4129\n",
      "Epoch 496/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2367 - val_loss: 0.4351\n",
      "Epoch 497/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2235 - val_loss: 0.4483\n",
      "Epoch 498/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2346 - val_loss: 0.4418\n",
      "Epoch 499/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2249 - val_loss: 0.4369\n",
      "Epoch 500/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2316 - val_loss: 0.4532\n",
      "Epoch 501/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2397 - val_loss: 0.4370\n",
      "Epoch 502/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2407 - val_loss: 0.4572\n",
      "Epoch 503/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2201 - val_loss: 0.4790\n",
      "Epoch 504/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2354 - val_loss: 0.4928\n",
      "Epoch 505/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2314 - val_loss: 0.4919\n",
      "Epoch 506/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2274 - val_loss: 0.4631\n",
      "Epoch 507/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2354 - val_loss: 0.4698\n",
      "Epoch 508/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2302 - val_loss: 0.4583\n",
      "Epoch 509/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2402 - val_loss: 0.4899\n",
      "Epoch 510/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2326 - val_loss: 0.4710\n",
      "Epoch 511/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2347 - val_loss: 0.4690\n",
      "Epoch 512/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2233 - val_loss: 0.4784\n",
      "Epoch 513/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2425 - val_loss: 0.4746\n",
      "Epoch 514/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2204 - val_loss: 0.4529\n",
      "Epoch 515/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2477 - val_loss: 0.4383\n",
      "Epoch 516/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2087 - val_loss: 0.4469\n",
      "Epoch 517/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2154 - val_loss: 0.4787\n",
      "Epoch 518/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2272 - val_loss: 0.4424\n",
      "Epoch 519/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2342 - val_loss: 0.4807\n",
      "Epoch 520/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2438 - val_loss: 0.4893\n",
      "Epoch 521/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2310 - val_loss: 0.4189\n",
      "Epoch 522/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2263 - val_loss: 0.4368\n",
      "Epoch 523/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2283 - val_loss: 0.4729\n",
      "Epoch 524/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2237 - val_loss: 0.4844\n",
      "Epoch 525/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2268 - val_loss: 0.4839\n",
      "Epoch 526/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2265 - val_loss: 0.4442\n",
      "Epoch 527/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2419 - val_loss: 0.4308\n",
      "Epoch 528/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2042 - val_loss: 0.4905\n",
      "Epoch 529/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2321 - val_loss: 0.5105\n",
      "Epoch 530/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2337 - val_loss: 0.4787\n",
      "Epoch 531/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2294 - val_loss: 0.4589\n",
      "Epoch 532/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2121 - val_loss: 0.4644\n",
      "Epoch 533/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2260 - val_loss: 0.5154\n",
      "Epoch 534/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.202 - 0s 4ms/step - loss: 0.2225 - val_loss: 0.5115\n",
      "Epoch 535/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.4672\n",
      "Epoch 536/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2251 - val_loss: 0.4805\n",
      "Epoch 537/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2088 - val_loss: 0.4713\n",
      "Epoch 538/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2416 - val_loss: 0.4463\n",
      "Epoch 539/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2161 - val_loss: 0.4427\n",
      "Epoch 540/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2169 - val_loss: 0.4233\n",
      "Epoch 541/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2108 - val_loss: 0.4544\n",
      "Epoch 542/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2256 - val_loss: 0.4747\n",
      "Epoch 543/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2298 - val_loss: 0.4794\n",
      "Epoch 544/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2244 - val_loss: 0.4780\n",
      "Epoch 545/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2136 - val_loss: 0.4615\n",
      "Epoch 546/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2232 - val_loss: 0.4113\n",
      "Epoch 547/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2276 - val_loss: 0.3994\n",
      "Epoch 548/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2279 - val_loss: 0.4416\n",
      "Epoch 549/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2236 - val_loss: 0.4520\n",
      "Epoch 550/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2289 - val_loss: 0.4735\n",
      "Epoch 551/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2275 - val_loss: 0.4417\n",
      "Epoch 552/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2301 - val_loss: 0.4753\n",
      "Epoch 553/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2188 - val_loss: 0.5203\n",
      "Epoch 554/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2252 - val_loss: 0.4682\n",
      "Epoch 555/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2214 - val_loss: 0.4456\n",
      "Epoch 556/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2116 - val_loss: 0.4924\n",
      "Epoch 557/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2331 - val_loss: 0.4775\n",
      "Epoch 558/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2172 - val_loss: 0.5009\n",
      "Epoch 559/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2076 - val_loss: 0.5224\n",
      "Epoch 560/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2182 - val_loss: 0.4728\n",
      "Epoch 561/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2411 - val_loss: 0.4628\n",
      "Epoch 562/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2098 - val_loss: 0.4765\n",
      "Epoch 563/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2203 - val_loss: 0.4954\n",
      "Epoch 564/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2153 - val_loss: 0.4805\n",
      "Epoch 565/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2131 - val_loss: 0.5226\n",
      "Epoch 566/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2179 - val_loss: 0.5180\n",
      "Epoch 567/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2101 - val_loss: 0.4656\n",
      "Epoch 568/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2042 - val_loss: 0.5025\n",
      "Epoch 569/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2038 - val_loss: 0.5266\n",
      "Epoch 570/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2181 - val_loss: 0.5301\n",
      "Epoch 571/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2157 - val_loss: 0.5291\n",
      "Epoch 572/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2235 - val_loss: 0.4951\n",
      "Epoch 573/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2140 - val_loss: 0.4969\n",
      "Epoch 574/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2196 - val_loss: 0.5173\n",
      "Epoch 575/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2249 - val_loss: 0.5035\n",
      "Epoch 576/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2162 - val_loss: 0.5116\n",
      "Epoch 577/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2158 - val_loss: 0.5055\n",
      "Epoch 578/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2172 - val_loss: 0.5268\n",
      "Epoch 579/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2244 - val_loss: 0.5379\n",
      "Epoch 580/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2142 - val_loss: 0.5432\n",
      "Epoch 581/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2196 - val_loss: 0.5122\n",
      "Epoch 582/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2155 - val_loss: 0.5303\n",
      "Epoch 583/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2198 - val_loss: 0.5374\n",
      "Epoch 584/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2177 - val_loss: 0.5217\n",
      "Epoch 585/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2300 - val_loss: 0.4720\n",
      "Epoch 586/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2141 - val_loss: 0.4747\n",
      "Epoch 587/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2261 - val_loss: 0.5346\n",
      "Epoch 588/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2251 - val_loss: 0.5189\n",
      "Epoch 589/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2096 - val_loss: 0.5433\n",
      "Epoch 590/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2278 - val_loss: 0.5417\n",
      "Epoch 591/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2052 - val_loss: 0.5066\n",
      "Epoch 592/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2114 - val_loss: 0.5217\n",
      "Epoch 593/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2242 - val_loss: 0.5004\n",
      "Epoch 594/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2343 - val_loss: 0.5017\n",
      "Epoch 595/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2160 - val_loss: 0.4875\n",
      "Epoch 596/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2062 - val_loss: 0.5082\n",
      "Epoch 597/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2178 - val_loss: 0.5365\n",
      "Epoch 598/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2121 - val_loss: 0.5197\n",
      "Epoch 599/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2205 - val_loss: 0.5204\n",
      "Epoch 600/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2101 - val_loss: 0.5011\n",
      "Epoch 601/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2244 - val_loss: 0.5140\n",
      "Epoch 602/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2193 - val_loss: 0.4827\n",
      "Epoch 603/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2251 - val_loss: 0.5298\n",
      "Epoch 604/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2232 - val_loss: 0.5236\n",
      "Epoch 605/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2200 - val_loss: 0.4960\n",
      "Epoch 606/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2230 - val_loss: 0.5180\n",
      "Epoch 607/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2187 - val_loss: 0.5106\n",
      "Epoch 608/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2107 - val_loss: 0.5261\n",
      "Epoch 609/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2222 - val_loss: 0.5152\n",
      "Epoch 610/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2120 - val_loss: 0.4940\n",
      "Epoch 611/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.5259\n",
      "Epoch 612/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2318 - val_loss: 0.5591\n",
      "Epoch 613/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2039 - val_loss: 0.5391\n",
      "Epoch 614/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2099 - val_loss: 0.5149\n",
      "Epoch 615/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2062 - val_loss: 0.4945\n",
      "Epoch 616/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.4816\n",
      "Epoch 617/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2062 - val_loss: 0.4817\n",
      "Epoch 618/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2262 - val_loss: 0.5210\n",
      "Epoch 619/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2006 - val_loss: 0.5160\n",
      "Epoch 620/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2079 - val_loss: 0.4831\n",
      "Epoch 621/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2122 - val_loss: 0.5222\n",
      "Epoch 622/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2193 - val_loss: 0.5658\n",
      "Epoch 623/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2245 - val_loss: 0.5543\n",
      "Epoch 624/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.5247\n",
      "Epoch 625/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2088 - val_loss: 0.5364\n",
      "Epoch 626/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2147 - val_loss: 0.5110\n",
      "Epoch 627/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2135 - val_loss: 0.5063\n",
      "Epoch 628/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2002 - val_loss: 0.5208\n",
      "Epoch 629/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2191 - val_loss: 0.5399\n",
      "Epoch 630/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2202 - val_loss: 0.5301\n",
      "Epoch 631/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1980 - val_loss: 0.5251\n",
      "Epoch 632/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2085 - val_loss: 0.5286\n",
      "Epoch 633/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2088 - val_loss: 0.5352\n",
      "Epoch 634/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2077 - val_loss: 0.5688\n",
      "Epoch 635/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.5353\n",
      "Epoch 636/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2182 - val_loss: 0.5412\n",
      "Epoch 637/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1935 - val_loss: 0.5514\n",
      "Epoch 638/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2180 - val_loss: 0.5279\n",
      "Epoch 639/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.218 - 0s 5ms/step - loss: 0.2073 - val_loss: 0.5064\n",
      "Epoch 640/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2171 - val_loss: 0.5052\n",
      "Epoch 641/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2162 - val_loss: 0.5275\n",
      "Epoch 642/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2068 - val_loss: 0.5373\n",
      "Epoch 643/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2049 - val_loss: 0.5442\n",
      "Epoch 644/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1907 - val_loss: 0.5700\n",
      "Epoch 645/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2103 - val_loss: 0.5452\n",
      "Epoch 646/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2054 - val_loss: 0.5116\n",
      "Epoch 647/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2158 - val_loss: 0.5260\n",
      "Epoch 648/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1981 - val_loss: 0.5517\n",
      "Epoch 649/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2206 - val_loss: 0.5558\n",
      "Epoch 650/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2026 - val_loss: 0.5698\n",
      "Epoch 651/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2053 - val_loss: 0.5821\n",
      "Epoch 652/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2170 - val_loss: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 653/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2159 - val_loss: 0.5789\n",
      "Epoch 654/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2030 - val_loss: 0.5659\n",
      "Epoch 655/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2129 - val_loss: 0.5961\n",
      "Epoch 656/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.5684\n",
      "Epoch 657/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2163 - val_loss: 0.5502\n",
      "Epoch 658/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1980 - val_loss: 0.5843\n",
      "Epoch 659/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2219 - val_loss: 0.5636\n",
      "Epoch 660/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2103 - val_loss: 0.5626\n",
      "Epoch 661/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2079 - val_loss: 0.5557\n",
      "Epoch 662/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2093 - val_loss: 0.5645\n",
      "Epoch 663/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2101 - val_loss: 0.5430\n",
      "Epoch 664/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2172 - val_loss: 0.5353\n",
      "Epoch 665/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2176 - val_loss: 0.5323\n",
      "Epoch 666/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2114 - val_loss: 0.4750\n",
      "Epoch 667/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2084 - val_loss: 0.5345\n",
      "Epoch 668/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2139 - val_loss: 0.5612\n",
      "Epoch 669/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1849 - val_loss: 0.5778\n",
      "Epoch 670/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1965 - val_loss: 0.5810\n",
      "Epoch 671/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2131 - val_loss: 0.5940\n",
      "Epoch 672/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.188 - 0s 5ms/step - loss: 0.2183 - val_loss: 0.5773\n",
      "Epoch 673/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2219 - val_loss: 0.5907\n",
      "Epoch 674/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2050 - val_loss: 0.5976\n",
      "Epoch 675/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2198 - val_loss: 0.5922\n",
      "Epoch 676/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1976 - val_loss: 0.5844\n",
      "Epoch 677/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.5926\n",
      "Epoch 678/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2099 - val_loss: 0.5927\n",
      "Epoch 679/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1989 - val_loss: 0.5888\n",
      "Epoch 680/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2154 - val_loss: 0.6060\n",
      "Epoch 681/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2004 - val_loss: 0.6084\n",
      "Epoch 682/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.6043\n",
      "Epoch 683/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1861 - val_loss: 0.5972\n",
      "Epoch 684/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1973 - val_loss: 0.6006\n",
      "Epoch 685/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2010 - val_loss: 0.6048\n",
      "Epoch 686/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.6318\n",
      "Epoch 687/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2070 - val_loss: 0.6074\n",
      "Epoch 688/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1965 - val_loss: 0.5811\n",
      "Epoch 689/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2023 - val_loss: 0.5713\n",
      "Epoch 690/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1943 - val_loss: 0.5779\n",
      "Epoch 691/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1952 - val_loss: 0.5806\n",
      "Epoch 692/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1954 - val_loss: 0.5979\n",
      "Epoch 693/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2137 - val_loss: 0.6059\n",
      "Epoch 694/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.5869\n",
      "Epoch 695/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1954 - val_loss: 0.5933\n",
      "Epoch 696/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2052 - val_loss: 0.5785\n",
      "Epoch 697/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1981 - val_loss: 0.5784\n",
      "Epoch 698/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1974 - val_loss: 0.5853\n",
      "Epoch 699/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2075 - val_loss: 0.5738\n",
      "Epoch 700/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.5743\n",
      "Epoch 701/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1869 - val_loss: 0.5938\n",
      "Epoch 702/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1908 - val_loss: 0.6016\n",
      "Epoch 703/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2023 - val_loss: 0.6235\n",
      "Epoch 704/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2082 - val_loss: 0.6185\n",
      "Epoch 705/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2060 - val_loss: 0.5710\n",
      "Epoch 706/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2049 - val_loss: 0.5450\n",
      "Epoch 707/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2021 - val_loss: 0.5471\n",
      "Epoch 708/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1974 - val_loss: 0.5437\n",
      "Epoch 709/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2065 - val_loss: 0.5433\n",
      "Epoch 710/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1986 - val_loss: 0.5506\n",
      "Epoch 711/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2019 - val_loss: 0.5862\n",
      "Epoch 712/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2162 - val_loss: 0.5501\n",
      "Epoch 713/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2061 - val_loss: 0.5787\n",
      "Epoch 714/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2029 - val_loss: 0.5562\n",
      "Epoch 715/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1998 - val_loss: 0.5387\n",
      "Epoch 716/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1954 - val_loss: 0.5738\n",
      "Epoch 717/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1903 - val_loss: 0.5591\n",
      "Epoch 718/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2068 - val_loss: 0.6107\n",
      "Epoch 719/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.6165\n",
      "Epoch 720/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1930 - val_loss: 0.6063\n",
      "Epoch 721/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1815 - val_loss: 0.6110\n",
      "Epoch 722/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2130 - val_loss: 0.6159\n",
      "Epoch 723/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2002 - val_loss: 0.6417\n",
      "Epoch 724/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1977 - val_loss: 0.6128\n",
      "Epoch 725/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2094 - val_loss: 0.5866\n",
      "Epoch 726/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1964 - val_loss: 0.5766\n",
      "Epoch 727/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2066 - val_loss: 0.5811\n",
      "Epoch 728/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2096 - val_loss: 0.5939\n",
      "Epoch 729/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1956 - val_loss: 0.6027\n",
      "Epoch 730/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1891 - val_loss: 0.6193\n",
      "Epoch 731/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2121 - val_loss: 0.6142\n",
      "Epoch 732/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1985 - val_loss: 0.6119\n",
      "Epoch 733/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2050 - val_loss: 0.6314\n",
      "Epoch 734/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2051 - val_loss: 0.5966\n",
      "Epoch 735/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1830 - val_loss: 0.5884\n",
      "Epoch 736/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1921 - val_loss: 0.5915\n",
      "Epoch 737/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2068 - val_loss: 0.5962\n",
      "Epoch 738/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1937 - val_loss: 0.5962\n",
      "Epoch 739/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1988 - val_loss: 0.5771\n",
      "Epoch 740/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1987 - val_loss: 0.5182\n",
      "Epoch 741/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1846 - val_loss: 0.5313\n",
      "Epoch 742/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2032 - val_loss: 0.5651\n",
      "Epoch 743/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1956 - val_loss: 0.5675\n",
      "Epoch 744/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1887 - val_loss: 0.5737\n",
      "Epoch 745/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.163 - 0s 4ms/step - loss: 0.1908 - val_loss: 0.5902\n",
      "Epoch 746/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1943 - val_loss: 0.5942\n",
      "Epoch 747/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1975 - val_loss: 0.6112\n",
      "Epoch 748/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2038 - val_loss: 0.5679\n",
      "Epoch 749/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2099 - val_loss: 0.5769\n",
      "Epoch 750/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1922 - val_loss: 0.6005\n",
      "Epoch 751/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2076 - val_loss: 0.5458\n",
      "Epoch 752/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2097 - val_loss: 0.5489\n",
      "Epoch 753/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2175 - val_loss: 0.5706\n",
      "Epoch 754/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1916 - val_loss: 0.6029\n",
      "Epoch 755/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2033 - val_loss: 0.5867\n",
      "Epoch 756/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1960 - val_loss: 0.5594\n",
      "Epoch 757/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1987 - val_loss: 0.5614\n",
      "Epoch 758/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1852 - val_loss: 0.5618\n",
      "Epoch 759/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1907 - val_loss: 0.5917\n",
      "Epoch 760/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2125 - val_loss: 0.5993\n",
      "Epoch 761/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2006 - val_loss: 0.6212\n",
      "Epoch 762/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.5837\n",
      "Epoch 763/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1948 - val_loss: 0.5714\n",
      "Epoch 764/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1965 - val_loss: 0.5634\n",
      "Epoch 765/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1985 - val_loss: 0.5745\n",
      "Epoch 766/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1891 - val_loss: 0.5709\n",
      "Epoch 767/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1848 - val_loss: 0.5656\n",
      "Epoch 768/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1898 - val_loss: 0.5576\n",
      "Epoch 769/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1963 - val_loss: 0.5815\n",
      "Epoch 770/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1803 - val_loss: 0.6359\n",
      "Epoch 771/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1930 - val_loss: 0.6388\n",
      "Epoch 772/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1969 - val_loss: 0.6242\n",
      "Epoch 773/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2066 - val_loss: 0.6014\n",
      "Epoch 774/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1963 - val_loss: 0.5753\n",
      "Epoch 775/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1943 - val_loss: 0.5645\n",
      "Epoch 776/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1986 - val_loss: 0.5877\n",
      "Epoch 777/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2083 - val_loss: 0.6317\n",
      "Epoch 778/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1911 - val_loss: 0.6518\n",
      "Epoch 779/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2022 - val_loss: 0.5977\n",
      "Epoch 780/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1916 - val_loss: 0.5866\n",
      "Epoch 781/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2134 - val_loss: 0.5968\n",
      "Epoch 782/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.5988\n",
      "Epoch 783/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1948 - val_loss: 0.6164\n",
      "Epoch 784/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2099 - val_loss: 0.6001\n",
      "Epoch 785/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1905 - val_loss: 0.6039\n",
      "Epoch 786/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1931 - val_loss: 0.6246\n",
      "Epoch 787/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1983 - val_loss: 0.6293\n",
      "Epoch 788/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1888 - val_loss: 0.6403\n",
      "Epoch 789/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2023 - val_loss: 0.5983\n",
      "Epoch 790/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1833 - val_loss: 0.5992\n",
      "Epoch 791/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1857 - val_loss: 0.5835\n",
      "Epoch 792/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1953 - val_loss: 0.5954\n",
      "Epoch 793/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.160 - 0s 5ms/step - loss: 0.1806 - val_loss: 0.6355\n",
      "Epoch 794/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1949 - val_loss: 0.6404\n",
      "Epoch 795/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1879 - val_loss: 0.6323\n",
      "Epoch 796/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1913 - val_loss: 0.6194\n",
      "Epoch 797/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1981 - val_loss: 0.6134\n",
      "Epoch 798/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2126 - val_loss: 0.5693\n",
      "Epoch 799/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.4779\n",
      "Epoch 800/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1946 - val_loss: 0.4780\n",
      "Epoch 801/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.5570\n",
      "Epoch 802/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1704 - val_loss: 0.6083\n",
      "Epoch 803/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2005 - val_loss: 0.5982\n",
      "Epoch 804/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1878 - val_loss: 0.5631\n",
      "Epoch 805/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1963 - val_loss: 0.5853\n",
      "Epoch 806/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2249 - val_loss: 0.6459\n",
      "Epoch 807/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1864 - val_loss: 0.6325\n",
      "Epoch 808/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1842 - val_loss: 0.5840\n",
      "Epoch 809/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1879 - val_loss: 0.5804\n",
      "Epoch 810/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1812 - val_loss: 0.5920\n",
      "Epoch 811/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2018 - val_loss: 0.6159\n",
      "Epoch 812/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1804 - val_loss: 0.6351\n",
      "Epoch 813/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2094 - val_loss: 0.6341\n",
      "Epoch 814/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1935 - val_loss: 0.6311\n",
      "Epoch 815/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1804 - val_loss: 0.6462\n",
      "Epoch 816/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1962 - val_loss: 0.6777\n",
      "Epoch 817/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1946 - val_loss: 0.6343\n",
      "Epoch 818/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1969 - val_loss: 0.6256\n",
      "Epoch 819/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1971 - val_loss: 0.6432\n",
      "Epoch 820/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.187 - 0s 4ms/step - loss: 0.1858 - val_loss: 0.6557\n",
      "Epoch 821/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2141 - val_loss: 0.6207\n",
      "Epoch 822/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1661 - val_loss: 0.5926\n",
      "Epoch 823/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1835 - val_loss: 0.5968\n",
      "Epoch 824/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1807 - val_loss: 0.6136\n",
      "Epoch 825/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1728 - val_loss: 0.5975\n",
      "Epoch 826/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.6049\n",
      "Epoch 827/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1833 - val_loss: 0.6345\n",
      "Epoch 828/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.6641\n",
      "Epoch 829/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2022 - val_loss: 0.6411\n",
      "Epoch 830/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1797 - val_loss: 0.6635\n",
      "Epoch 831/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1772 - val_loss: 0.6433\n",
      "Epoch 832/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1696 - val_loss: 0.5790\n",
      "Epoch 833/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2014 - val_loss: 0.5621\n",
      "Epoch 834/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1936 - val_loss: 0.5459\n",
      "Epoch 835/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2084 - val_loss: 0.5909\n",
      "Epoch 836/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.244 - 0s 5ms/step - loss: 0.1967 - val_loss: 0.6253\n",
      "Epoch 837/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2081 - val_loss: 0.6125\n",
      "Epoch 838/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2087 - val_loss: 0.6044\n",
      "Epoch 839/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1823 - val_loss: 0.5671\n",
      "Epoch 840/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2034 - val_loss: 0.6072\n",
      "Epoch 841/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2058 - val_loss: 0.6793\n",
      "Epoch 842/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2000 - val_loss: 0.6908\n",
      "Epoch 843/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1814 - val_loss: 0.6541\n",
      "Epoch 844/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1846 - val_loss: 0.6263\n",
      "Epoch 845/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.235 - 0s 5ms/step - loss: 0.1988 - val_loss: 0.5835\n",
      "Epoch 846/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1756 - val_loss: 0.5896\n",
      "Epoch 847/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1822 - val_loss: 0.6353\n",
      "Epoch 848/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1897 - val_loss: 0.6236\n",
      "Epoch 849/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1886 - val_loss: 0.6611\n",
      "Epoch 850/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1917 - val_loss: 0.6845\n",
      "Epoch 851/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1951 - val_loss: 0.6766\n",
      "Epoch 852/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1801 - val_loss: 0.6471\n",
      "Epoch 853/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1852 - val_loss: 0.6249\n",
      "Epoch 854/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1908 - val_loss: 0.6556\n",
      "Epoch 855/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1827 - val_loss: 0.6642\n",
      "Epoch 856/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1767 - val_loss: 0.6525\n",
      "Epoch 857/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1862 - val_loss: 0.6012\n",
      "Epoch 858/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2015 - val_loss: 0.6415\n",
      "Epoch 859/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1955 - val_loss: 0.6049\n",
      "Epoch 860/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2061 - val_loss: 0.6146\n",
      "Epoch 861/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1714 - val_loss: 0.6149\n",
      "Epoch 862/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1953 - val_loss: 0.6038\n",
      "Epoch 863/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1968 - val_loss: 0.6291\n",
      "Epoch 864/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1773 - val_loss: 0.6421\n",
      "Epoch 865/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1895 - val_loss: 0.6377\n",
      "Epoch 866/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1926 - val_loss: 0.6481\n",
      "Epoch 867/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1881 - val_loss: 0.6327\n",
      "Epoch 868/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1799 - val_loss: 0.6151\n",
      "Epoch 869/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1897 - val_loss: 0.6395\n",
      "Epoch 870/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1968 - val_loss: 0.6557\n",
      "Epoch 871/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1842 - val_loss: 0.6432\n",
      "Epoch 872/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1793 - val_loss: 0.6150\n",
      "Epoch 873/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1776 - val_loss: 0.6380\n",
      "Epoch 874/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1752 - val_loss: 0.6701\n",
      "Epoch 875/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1875 - val_loss: 0.7016\n",
      "Epoch 876/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1745 - val_loss: 0.6684\n",
      "Epoch 877/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1910 - val_loss: 0.6654\n",
      "Epoch 878/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1887 - val_loss: 0.6914\n",
      "Epoch 879/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1886 - val_loss: 0.6191\n",
      "Epoch 880/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2010 - val_loss: 0.5979\n",
      "Epoch 881/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1849 - val_loss: 0.6174\n",
      "Epoch 882/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1878 - val_loss: 0.6341\n",
      "Epoch 883/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1779 - val_loss: 0.6449\n",
      "Epoch 884/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1907 - val_loss: 0.6117\n",
      "Epoch 885/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1887 - val_loss: 0.6074\n",
      "Epoch 886/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1812 - val_loss: 0.5964\n",
      "Epoch 887/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2010 - val_loss: 0.5687\n",
      "Epoch 888/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1958 - val_loss: 0.6089\n",
      "Epoch 889/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1889 - val_loss: 0.6433\n",
      "Epoch 890/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2045 - val_loss: 0.5777\n",
      "Epoch 891/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1982 - val_loss: 0.5378\n",
      "Epoch 892/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1847 - val_loss: 0.5591\n",
      "Epoch 893/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1968 - val_loss: 0.5510\n",
      "Epoch 894/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1839 - val_loss: 0.5476\n",
      "Epoch 895/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1878 - val_loss: 0.5775\n",
      "Epoch 896/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1991 - val_loss: 0.5761\n",
      "Epoch 897/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1893 - val_loss: 0.5693\n",
      "Epoch 898/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1810 - val_loss: 0.5775\n",
      "Epoch 899/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1905 - val_loss: 0.5728\n",
      "Epoch 900/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1831 - val_loss: 0.6103\n",
      "Epoch 901/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1925 - val_loss: 0.5970\n",
      "Epoch 902/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1971 - val_loss: 0.6302\n",
      "Epoch 903/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2078 - val_loss: 0.6677\n",
      "Epoch 904/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1943 - val_loss: 0.6075\n",
      "Epoch 905/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.5808\n",
      "Epoch 906/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1814 - val_loss: 0.5806\n",
      "Epoch 907/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1750 - val_loss: 0.6104\n",
      "Epoch 908/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2069 - val_loss: 0.6109\n",
      "Epoch 909/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2086 - val_loss: 0.5820\n",
      "Epoch 910/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2127 - val_loss: 0.5901\n",
      "Epoch 911/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1826 - val_loss: 0.5907\n",
      "Epoch 912/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.280 - 0s 4ms/step - loss: 0.1954 - val_loss: 0.6117\n",
      "Epoch 913/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1951 - val_loss: 0.6347\n",
      "Epoch 914/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1775 - val_loss: 0.6303\n",
      "Epoch 915/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1774 - val_loss: 0.6328\n",
      "Epoch 916/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1862 - val_loss: 0.6512\n",
      "Epoch 917/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1984 - val_loss: 0.6298\n",
      "Epoch 918/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.6231\n",
      "Epoch 919/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1963 - val_loss: 0.5933\n",
      "Epoch 920/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1718 - val_loss: 0.5955\n",
      "Epoch 921/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1816 - val_loss: 0.6082\n",
      "Epoch 922/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1839 - val_loss: 0.6112\n",
      "Epoch 923/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2050 - val_loss: 0.5783\n",
      "Epoch 924/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1745 - val_loss: 0.5646\n",
      "Epoch 925/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1698 - val_loss: 0.5781\n",
      "Epoch 926/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1786 - val_loss: 0.5996\n",
      "Epoch 927/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1764 - val_loss: 0.6469\n",
      "Epoch 928/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1957 - val_loss: 0.6442\n",
      "Epoch 929/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1831 - val_loss: 0.6684\n",
      "Epoch 930/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1866 - val_loss: 0.6302\n",
      "Epoch 931/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1703 - val_loss: 0.5871\n",
      "Epoch 932/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1877 - val_loss: 0.5814\n",
      "Epoch 933/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1769 - val_loss: 0.6261\n",
      "Epoch 934/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.220 - 0s 5ms/step - loss: 0.1830 - val_loss: 0.6137\n",
      "Epoch 935/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1703 - val_loss: 0.6158\n",
      "Epoch 936/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1866 - val_loss: 0.6036\n",
      "Epoch 937/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1767 - val_loss: 0.6226\n",
      "Epoch 938/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1829 - val_loss: 0.6425\n",
      "Epoch 939/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1723 - val_loss: 0.6716\n",
      "Epoch 940/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1889 - val_loss: 0.6753\n",
      "Epoch 941/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1840 - val_loss: 0.7102\n",
      "Epoch 942/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1907 - val_loss: 0.6911\n",
      "Epoch 943/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1988 - val_loss: 0.7367\n",
      "Epoch 944/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.6675\n",
      "Epoch 945/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.6073\n",
      "Epoch 946/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1928 - val_loss: 0.5817\n",
      "Epoch 947/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1672 - val_loss: 0.6204\n",
      "Epoch 948/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1833 - val_loss: 0.6448\n",
      "Epoch 949/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1794 - val_loss: 0.6608\n",
      "Epoch 950/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.7324\n",
      "Epoch 951/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1945 - val_loss: 0.6300\n",
      "Epoch 952/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1832 - val_loss: 0.6138\n",
      "Epoch 953/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1745 - val_loss: 0.6173\n",
      "Epoch 954/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.6323\n",
      "Epoch 955/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1944 - val_loss: 0.6567\n",
      "Epoch 956/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2020 - val_loss: 0.7925\n",
      "Epoch 957/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1891 - val_loss: 0.6253\n",
      "Epoch 958/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1822 - val_loss: 0.5700\n",
      "Epoch 959/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1965 - val_loss: 0.5969\n",
      "Epoch 960/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1812 - val_loss: 0.6267\n",
      "Epoch 961/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1755 - val_loss: 0.6785\n",
      "Epoch 962/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1682 - val_loss: 0.7358\n",
      "Epoch 963/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1789 - val_loss: 0.7085\n",
      "Epoch 964/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1815 - val_loss: 0.6662\n",
      "Epoch 965/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1863 - val_loss: 0.6391\n",
      "Epoch 966/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1889 - val_loss: 0.6450\n",
      "Epoch 967/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1801 - val_loss: 0.6886\n",
      "Epoch 968/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1802 - val_loss: 0.6829\n",
      "Epoch 969/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1782 - val_loss: 0.6536\n",
      "Epoch 970/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1785 - val_loss: 0.6717\n",
      "Epoch 971/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1839 - val_loss: 0.6778\n",
      "Epoch 972/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1678 - val_loss: 0.6038\n",
      "Epoch 973/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1863 - val_loss: 0.5801\n",
      "Epoch 974/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1824 - val_loss: 0.6683\n",
      "Epoch 975/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1730 - val_loss: 0.6816\n",
      "Epoch 976/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1680 - val_loss: 0.6934\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1829 - val_loss: 0.6928\n",
      "Epoch 978/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1772 - val_loss: 0.6573\n",
      "Epoch 979/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1751 - val_loss: 0.6498\n",
      "Epoch 980/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1848 - val_loss: 0.6446\n",
      "Epoch 981/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1791 - val_loss: 0.6370\n",
      "Epoch 982/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.6352\n",
      "Epoch 983/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1824 - val_loss: 0.6635\n",
      "Epoch 984/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.6924\n",
      "Epoch 985/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1978 - val_loss: 0.6820\n",
      "Epoch 986/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1644 - val_loss: 0.6941\n",
      "Epoch 987/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2007 - val_loss: 0.6999\n",
      "Epoch 988/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1830 - val_loss: 0.6848\n",
      "Epoch 989/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2047 - val_loss: 0.6605\n",
      "Epoch 990/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1847 - val_loss: 0.6607\n",
      "Epoch 991/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1702 - val_loss: 0.6679\n",
      "Epoch 992/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1745 - val_loss: 0.6987\n",
      "Epoch 993/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1838 - val_loss: 0.7242\n",
      "Epoch 994/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1932 - val_loss: 0.7178\n",
      "Epoch 995/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1733 - val_loss: 0.6916\n",
      "Epoch 996/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1834 - val_loss: 0.6658\n",
      "Epoch 997/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1679 - val_loss: 0.6865\n",
      "Epoch 998/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1920 - val_loss: 0.6935\n",
      "Epoch 999/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1773 - val_loss: 0.7022\n",
      "Epoch 1000/1000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1858 - val_loss: 0.6505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212105ce7c0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data for at least 25 epochs. Also add in the validation data for later plotting. Optional: add in a batch_size of 256.\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          batch_size=100,\n",
    "          validation_data=(X_test, y_test), \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85        24\n",
      "           1       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.85      0.81      0.81        45\n",
      "weighted avg       0.84      0.82      0.82        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  1],\n",
       "       [ 7, 14]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Survived']=(model.predict(test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission_first.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/target value specification\n",
    "y_train = train['Survived'].ravel()\n",
    "train = train.drop(['Survived'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5760 candidates, totalling 17280 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16824/529777323.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#n_estimators = 1000, random_state = 42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\milad\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 6]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "grid = {'n_estimators': n_estimators,\n",
    "           'max_features': max_features,\n",
    "           'max_depth': max_depth,\n",
    "           'min_samples_split': min_samples_split,\n",
    "           'min_samples_leaf': min_samples_leaf,\n",
    "           'bootstrap': bootstrap}\n",
    "rf = RandomForestClassifier() #n_estimators = 1000, random_state = 42\n",
    "model = GridSearchCV(estimator = rf, param_grid = grid, cv = 3, verbose=1,scoring=\"accuracy\", n_jobs = -1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 600}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 1750 out of 1750 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['Survived']=model.predict(x_test)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission_second.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
